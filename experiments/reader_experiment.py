"""
Reader Experiment: Character Recognition with NeuroGym

Demonstrates supervised learning of visual character patterns using a spiking
neural network trained with the NeuroGym framework.

Task:
- Recognize 5x5 binary pixel patterns of letters A, B, C
- Handle noisy inputs (5% pixel flips)
- Use winner-take-all competition
- Visualize learned receptive fields

Key Concepts:
- Visual pattern recognition
- Supervised learning with NeuroGym
- Lateral inhibition (winner-take-all)
- Receptive field visualization
- Noise robustness
"""

import numpy as np
import matplotlib.pyplot as plt
import sys
import os

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from circuit import NeuralCircuit
from neuro_gym import NeuroGym


# ============================================================================
# Letter Patterns (5x5 Binary Grids)
# ============================================================================

def create_letter_patterns():
    """
    Create perfect 5x5 binary patterns for letters A, B, C.

    Returns:
        Dictionary mapping letter labels to 5x5 numpy arrays
    """
    patterns = {}

    # Letter A: Pointy top, horizontal bar, legs at bottom
    patterns['A'] = np.array([
        [0, 1, 1, 1, 0],
        [1, 0, 0, 0, 1],
        [1, 1, 1, 1, 1],
        [1, 0, 0, 0, 1],
        [1, 0, 0, 0, 1]
    ])

    # Letter B: Flat top/bottom, middle bar, rounded right side
    patterns['B'] = np.array([
        [1, 1, 1, 1, 0],
        [1, 0, 0, 0, 1],
        [1, 1, 1, 1, 0],
        [1, 0, 0, 0, 1],
        [1, 1, 1, 1, 0]
    ])

    # Letter C: Top/bottom horizontal bars, left vertical bar
    patterns['C'] = np.array([
        [0, 1, 1, 1, 1],
        [1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0],
        [1, 0, 0, 0, 0],
        [0, 1, 1, 1, 1]
    ])

    return patterns


def add_noise(pattern, noise_level=0.05):
    """
    Add noise to a binary pattern by randomly flipping pixels.

    Args:
        pattern: 5x5 binary array
        noise_level: Probability of flipping each pixel (default 5%)

    Returns:
        Noisy pattern (5x5 array)
    """
    noisy = pattern.copy()
    flip_mask = np.random.rand(*pattern.shape) < noise_level
    noisy[flip_mask] = 1 - noisy[flip_mask]  # Flip 0->1, 1->0
    return noisy


def generate_dataset(num_samples=1000, noise_level=0.05):
    """
    Generate training dataset with noisy letter patterns.

    Process:
    1. Randomly select a letter (A, B, or C)
    2. Get perfect pattern for that letter
    3. Add noise (flip 5% of pixels)
    4. Flatten to 1D array (25 values)
    5. Assign integer label (A=0, B=1, C=2)

    Args:
        num_samples: Number of samples to generate
        noise_level: Probability of pixel flip (default 5%)

    Returns:
        task_data: Dictionary with 'inputs' and 'labels'
    """
    patterns = create_letter_patterns()
    letters = ['A', 'B', 'C']

    inputs = []
    labels = []

    for _ in range(num_samples):
        # Randomly select a letter
        letter = np.random.choice(letters)
        label = letters.index(letter)  # A=0, B=1, C=2

        # Get pattern and add noise
        pattern = patterns[letter]
        noisy_pattern = add_noise(pattern, noise_level)

        # Flatten to 1D (5x5 -> 25)
        flat_pattern = noisy_pattern.flatten()

        inputs.append(flat_pattern)
        labels.append(label)

    task_data = {
        'inputs': np.array(inputs),
        'labels': np.array(labels)
    }

    return task_data


# ============================================================================
# Visualization
# ============================================================================

def visualize_letter_patterns():
    """
    Display the perfect letter patterns used for training.
    """
    patterns = create_letter_patterns()
    letters = ['A', 'B', 'C']

    fig, axes = plt.subplots(1, 3, figsize=(10, 3))
    fig.suptitle('Perfect Letter Patterns (5x5 Binary Grids)',
                 fontsize=14, fontweight='bold')

    for i, letter in enumerate(letters):
        ax = axes[i]
        pattern = patterns[letter]

        ax.imshow(pattern, cmap='binary', interpolation='nearest')
        ax.set_title(f"Letter {letter} (Label {i})", fontsize=12, fontweight='bold')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.grid(True, color='gray', linewidth=0.5)

        # Add grid lines
        for x in range(6):
            ax.axhline(x - 0.5, color='gray', linewidth=0.5)
            ax.axvline(x - 0.5, color='gray', linewidth=0.5)

    plt.tight_layout()
    plt.savefig('outputs/reader_perfect_patterns.png', dpi=150, bbox_inches='tight')
    print("Perfect patterns saved to 'outputs/reader_perfect_patterns.png'")
    plt.close()


def visualize_noisy_samples(task_data, num_samples=9):
    """
    Visualize sample noisy patterns from dataset.

    Args:
        task_data: Generated dataset
        num_samples: Number of samples to show
    """
    fig, axes = plt.subplots(3, 3, figsize=(9, 9))
    fig.suptitle('Sample Noisy Training Data (5% Pixel Flips)',
                 fontsize=14, fontweight='bold')

    for i in range(num_samples):
        ax = axes[i // 3, i % 3]

        # Get sample
        flat_pattern = task_data['inputs'][i]
        label = task_data['labels'][i]
        letter = ['A', 'B', 'C'][label]

        # Reshape to 5x5
        pattern = flat_pattern.reshape(5, 5)

        ax.imshow(pattern, cmap='binary', interpolation='nearest')
        ax.set_title(f"Sample {i}: {letter} (Label {label})", fontsize=10)
        ax.set_xticks([])
        ax.set_yticks([])

        # Add grid
        for x in range(6):
            ax.axhline(x - 0.5, color='gray', linewidth=0.5)
            ax.axvline(x - 0.5, color='gray', linewidth=0.5)

    plt.tight_layout()
    plt.savefig('outputs/reader_noisy_samples.png', dpi=150, bbox_inches='tight')
    print("Noisy samples saved to 'outputs/reader_noisy_samples.png'")
    plt.close()


def visualize_receptive_fields(circuit):
    """
    Visualize learned receptive fields (synaptic weights) as heatmaps.

    After training, each neuron should learn to recognize its target letter.
    The weight pattern should resemble the letter:
    - Neuron 0 weights should look like 'A'
    - Neuron 1 weights should look like 'B'
    - Neuron 2 weights should look like 'C'

    Args:
        circuit: Trained NeuralCircuit
    """
    print("\n" + "="*70)
    print("RECEPTIVE FIELD VISUALIZATION")
    print("="*70)

    fig, axes = plt.subplots(1, 3, figsize=(12, 4))
    fig.suptitle('Learned Receptive Fields (What Each Neuron Recognizes)',
                 fontsize=14, fontweight='bold')

    letters = ['A', 'B', 'C']

    for neuron_id in range(3):
        ax = axes[neuron_id]

        # Get weights for this neuron (25 values -> 5x5 grid)
        weights = circuit.get_weights(neuron_id)
        receptive_field = weights.reshape(5, 5)

        # Plot as heatmap
        im = ax.imshow(receptive_field, cmap='RdBu_r', interpolation='nearest',
                      vmin=0, vmax=np.max(weights) if np.max(weights) > 0 else 1)

        ax.set_title(f"Neuron {neuron_id}: Letter {letters[neuron_id]}",
                    fontsize=12, fontweight='bold')
        ax.set_xticks([])
        ax.set_yticks([])

        # Add grid
        for x in range(6):
            ax.axhline(x - 0.5, color='black', linewidth=0.5, alpha=0.3)
            ax.axvline(x - 0.5, color='black', linewidth=0.5, alpha=0.3)

        # Add colorbar
        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

        # Print weight statistics
        print(f"\nNeuron {neuron_id} (Letter {letters[neuron_id]}):")
        print(f"  Weight range: [{np.min(weights):.2f}, {np.max(weights):.2f}]")
        print(f"  Mean weight: {np.mean(weights):.2f}")
        print(f"  Std weight: {np.std(weights):.2f}")

    plt.tight_layout()
    plt.savefig('outputs/reader_receptive_fields.png', dpi=150, bbox_inches='tight')
    print(f"\nReceptive fields saved to 'outputs/reader_receptive_fields.png'")
    print("="*70)


def test_recognition(circuit, task_data, gym, num_test=20):
    """
    Test the trained circuit on samples and show predictions.

    Args:
        circuit: Trained NeuralCircuit
        task_data: Dataset
        gym: NeuroGym instance
        num_test: Number of samples to test
    """
    print("\n" + "="*70)
    print("TESTING CHARACTER RECOGNITION")
    print("="*70)

    letters = ['A', 'B', 'C']
    correct = 0

    for i in range(num_test):
        input_pattern = task_data['inputs'][i]
        target_label = task_data['labels'][i]
        target_letter = letters[target_label]

        # Forward pass (no learning, no teacher forcing)
        input_spikes = input_pattern * gym.input_scale
        I_ext = np.ones(circuit.num_neurons) * gym.baseline_current

        output_spikes = circuit.step(
            input_spikes=input_spikes,
            I_ext=I_ext,
            learning=False
        )

        # Get prediction
        fired_neurons = np.where(output_spikes)[0]
        if len(fired_neurons) > 0:
            predicted_label = fired_neurons[0]
            predicted_letter = letters[predicted_label]
            is_correct = (predicted_label == target_label)
        else:
            predicted_letter = "?"
            is_correct = False

        if is_correct:
            correct += 1

        status = "‚úì" if is_correct else "‚úó"
        print(f"  Sample {i:2d}: Target={target_letter}, Predicted={predicted_letter} {status}")

    accuracy = correct / num_test
    print(f"\nTest Accuracy: {accuracy*100:.1f}% ({correct}/{num_test})")
    print("="*70)


# ============================================================================
# Main Experiment
# ============================================================================

def run_reader_experiment():
    """
    Run the complete character recognition experiment.

    Steps:
    1. Create letter patterns (A, B, C)
    2. Generate noisy dataset (1000 samples)
    3. Build neural circuit with lateral inhibition
    4. Train using NeuroGym until convergence
    5. Visualize learned receptive fields
    6. Test recognition performance
    """
    print("\n")
    print("‚ïî" + "‚ïê"*68 + "‚ïó")
    print("‚ïë" + " "*17 + "READER EXPERIMENT" + " "*33 + "‚ïë")
    print("‚ïë" + " "*14 + "Character Recognition with NeuroGym" + " "*20 + "‚ïë")
    print("‚ïö" + "‚ïê"*68 + "‚ïù")
    print()

    # ========== Step 1: Visualize Perfect Patterns ==========
    print("Step 1: Creating Perfect Letter Patterns...")
    visualize_letter_patterns()
    patterns = create_letter_patterns()
    print("  Letter A (Label 0): 5x5 binary grid")
    print("  Letter B (Label 1): 5x5 binary grid")
    print("  Letter C (Label 2): 5x5 binary grid")
    print()

    # ========== Step 2: Generate Dataset ==========
    print("Step 2: Generating Noisy Training Dataset...")
    num_samples = 1000
    noise_level = 0.05  # 5% pixel flips

    task_data = generate_dataset(num_samples=num_samples, noise_level=noise_level)

    print(f"  Generated {num_samples} samples")
    print(f"  Noise level: {noise_level*100:.0f}% pixel flips")
    print(f"  Input shape: {task_data['inputs'].shape} (samples x pixels)")
    print(f"  Labels: {np.bincount(task_data['labels'])} samples per class")
    print()

    # Visualize noisy samples
    visualize_noisy_samples(task_data, num_samples=9)

    # ========== Step 3: Build Neural Circuit ==========
    print("Step 3: Building Neural Circuit...")
    circuit = NeuralCircuit(
        num_neurons=3,          # One neuron per letter (A, B, C)
        input_channels=25,      # 5x5 = 25 pixels
        dt=1.0,
        max_delay=5,
        neuron_params={
            'tau_m': 20.0,          # Standard learning config
            'tau_trace': 20.0,
            'theta_base': -65.0,    # Standard learning config
            'v_rest': -70.0,
            'v_reset': -75.0,
            'u_increment': 0.1,     # Reduced adaptation
            'theta_increment': 0.05,
            'weight_min': 0.0,
            'weight_max': 10.0      # Standard learning config
        }
    )

    # Initialize weights to small random values
    for i in range(circuit.num_neurons):
        circuit.set_weights(i, np.random.rand(25) * 0.1)

    # CRITICAL: Set lateral inhibition (winner-take-all)
    circuit.set_inhibition(strength=5.0)

    print(f"  Neurons: {circuit.num_neurons} (one per letter)")
    print(f"  Input channels: {circuit.input_channels} (5x5 grid)")
    print(f"  Lateral inhibition: {circuit.inhibition_strength:.1f} mV (winner-take-all)")
    print(f"  Initial weights: Random [0.0, 0.1]")
    print()

    # ========== Step 4: Train with NeuroGym ==========
    print("Step 4: Training with NeuroGym...")
    gym = NeuroGym(
        circuit=circuit,
        task_data=task_data,
        input_scale=120.0,      # Strong input for reliable firing
        teacher_current=200.0,  # Strong teacher forcing
        baseline_current=15.0   # Moderate baseline for excitability
    )

    # Train until convergence
    final_acc = gym.train_until_converged(
        target_acc=0.95,        # Target 95% accuracy
        max_epochs=100,         # Maximum 100 epochs
        eval_every=5,           # Evaluate every 5 epochs
        early_stop_patience=20, # Stop if no improvement for 20 epochs
        verbose=True
    )

    print()

    # ========== Step 5: Visualize Receptive Fields ==========
    print("Step 5: Analyzing Learned Receptive Fields...")
    visualize_receptive_fields(circuit)
    print()

    # ========== Step 6: Test Recognition ==========
    print("Step 6: Testing Recognition on New Samples...")
    test_recognition(circuit, task_data, gym, num_test=20)
    print()

    # ========== Summary ==========
    print("\n" + "="*70)
    print("EXPERIMENT SUMMARY")
    print("="*70)

    print("\nüìä Results:")
    print(f"  Training samples: {num_samples}")
    print(f"  Noise level: {noise_level*100:.0f}%")
    print(f"  Final accuracy: {final_acc*100:.1f}%")
    print(f"  Epochs trained: {gym.current_epoch}")

    print("\nüß† Architecture:")
    print(f"  3 neurons (A, B, C)")
    print(f"  25 inputs (5x5 pixel grid)")
    print(f"  Lateral inhibition: Winner-take-all")
    print(f"  Learning: STDP via NeuroGym")

    print("\nüéØ Key Insights:")
    print("  ‚úì SNNs can learn visual patterns")
    print("  ‚úì Lateral inhibition creates selectivity")
    print("  ‚úì Receptive fields emerge from training")
    print("  ‚úì Noise robustness through multiple examples")

    print("\nüìà Visualizations Generated:")
    print("  1. outputs/reader_perfect_patterns.png")
    print("  2. outputs/reader_noisy_samples.png")
    print("  3. outputs/reader_receptive_fields.png")

    # Assess performance
    if final_acc >= 0.95:
        status = "‚úÖ EXCELLENT: Achieved target accuracy!"
    elif final_acc >= 0.80:
        status = "‚úÖ GOOD: Strong recognition performance"
    elif final_acc >= 0.60:
        status = "‚ö†Ô∏è  PARTIAL: Some learning but needs improvement"
    else:
        status = "‚ùå POOR: Needs parameter tuning"

    print(f"\n{status}")
    print("="*70)


if __name__ == "__main__":
    # Set random seed for reproducibility
    np.random.seed(42)

    # Create outputs directory if it doesn't exist
    os.makedirs('outputs', exist_ok=True)

    # Run experiment
    run_reader_experiment()

    print("\n" + "="*70)
    print("EXPERIMENT COMPLETE")
    print("="*70)
    print("\nThis demonstrates:")
    print("  ‚úì Visual pattern recognition with SNNs")
    print("  ‚úì Supervised learning via NeuroGym")
    print("  ‚úì Winner-take-all with lateral inhibition")
    print("  ‚úì Receptive field emergence and visualization")
    print("  ‚úì Noise robustness in character recognition")
    print("\nThe network learned to read letters! üìñ‚ú®")
    print("="*70)

